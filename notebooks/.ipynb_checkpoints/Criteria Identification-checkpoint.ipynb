{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Delbert\\AppData\\Roaming\\Python\\Python36\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>cohort</th>\n",
       "      <th>intent</th>\n",
       "      <th>inclusion</th>\n",
       "      <th>exclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what are the risks of high risk pregnancy due ...</td>\n",
       "      <td>{'inclusion': ['high risk pregnancy due to his...</td>\n",
       "      <td>prediction</td>\n",
       "      <td>[high risk pregnancy due to history of preterm...</td>\n",
       "      <td>[family planning education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the most effective treatments for pat...</td>\n",
       "      <td>{'inclusion': ['cardiac arrest with successful...</td>\n",
       "      <td>estimation</td>\n",
       "      <td>[cardiac arrest with successful resuscitation,...</td>\n",
       "      <td>[loss of voice, age=95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the spectrum of illness severity and c...</td>\n",
       "      <td>{'inclusion': [], 'exclusion': ['deep venous t...</td>\n",
       "      <td>incidence</td>\n",
       "      <td>[]</td>\n",
       "      <td>[deep venous thrombosis of upper extremity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can disorder of eye region care be modifie...</td>\n",
       "      <td>{'inclusion': ['disorder of eye region'], 'exc...</td>\n",
       "      <td>prediction</td>\n",
       "      <td>[disorder of eye region]</td>\n",
       "      <td>[septicemia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Should 5bromo3 pyrrolidin1ylsulfonyl 1hindole2...</td>\n",
       "      <td>{'inclusion': ['5-bromo-3-(pyrrolidin-1-ylsulf...</td>\n",
       "      <td>estimation</td>\n",
       "      <td>[5-bromo-3-(pyrrolidin-1-ylsulfonyl)-1h-indole...</td>\n",
       "      <td>[history of repair of coarctation of aorta]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  what are the risks of high risk pregnancy due ...   \n",
       "1  what are the most effective treatments for pat...   \n",
       "2  what is the spectrum of illness severity and c...   \n",
       "3  How can disorder of eye region care be modifie...   \n",
       "4  Should 5bromo3 pyrrolidin1ylsulfonyl 1hindole2...   \n",
       "\n",
       "                                              cohort      intent  \\\n",
       "0  {'inclusion': ['high risk pregnancy due to his...  prediction   \n",
       "1  {'inclusion': ['cardiac arrest with successful...  estimation   \n",
       "2  {'inclusion': [], 'exclusion': ['deep venous t...   incidence   \n",
       "3  {'inclusion': ['disorder of eye region'], 'exc...  prediction   \n",
       "4  {'inclusion': ['5-bromo-3-(pyrrolidin-1-ylsulf...  estimation   \n",
       "\n",
       "                                           inclusion  \\\n",
       "0  [high risk pregnancy due to history of preterm...   \n",
       "1  [cardiac arrest with successful resuscitation,...   \n",
       "2                                                 []   \n",
       "3                           [disorder of eye region]   \n",
       "4  [5-bromo-3-(pyrrolidin-1-ylsulfonyl)-1h-indole...   \n",
       "\n",
       "                                     exclusion  \n",
       "0                  [family planning education]  \n",
       "1                      [loss of voice, age=95]  \n",
       "2  [deep venous thrombosis of upper extremity]  \n",
       "3                                 [septicemia]  \n",
       "4  [history of repair of coarctation of aorta]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in text, create inclusion and exclusion columns, and clean\n",
    "df = pd.read_csv(\"data_tier-1_sample.csv\")\n",
    "df.reset_index(inplace = True)\n",
    "df.columns = [\"query\", \"cohort\", \"intent\"]\n",
    "# df = pd.read_csv(\"data_original.csv\")\n",
    "df[\"cohort\"] = df[\"cohort\"].apply(json.loads) \n",
    "\n",
    "df[\"inclusion\"] = [\"None\"]*len(df)\n",
    "df[\"exclusion\"] = [\"None\"]*len(df)\n",
    "\n",
    "cohort = df[\"cohort\"]\n",
    "for x in range(len(cohort)):\n",
    "    df[\"inclusion\"][x] = cohort[x][\"inclusion\"]\n",
    "    df[\"exclusion\"][x] = cohort[x][\"exclusion\"]\n",
    "    \n",
    "\n",
    "def clean_text(x):\n",
    "    x = re.sub(\"-\", \"\", x)\n",
    "    x = re.sub(\"\\(\", \" \", x)\n",
    "    x = re.sub(\"\\)\", \" \", x)\n",
    "    return x\n",
    "    \n",
    "df[\"query\"] = df[\"query\"].apply(clean_text)\n",
    "    \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)\n",
    "\n",
    "# Creating labels for each token based on exclusion and inclusion criteria\n",
    "final_labels = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    tokenized_query = tokenizer.tokenize(row[\"query\"])\n",
    "    labels = [\"Neither\"]*len(tokenized_query)\n",
    "    tokenized_inclusion = [tokenizer.tokenize(x) for x in row[\"inclusion\"]]\n",
    "    tokenized_exclusion = [tokenizer.tokenize(x) for x in row[\"exclusion\"]]\n",
    "    \n",
    "    for criteria in tokenized_inclusion:\n",
    "        for token in range(int(len(tokenized_query)-len(criteria))+1):\n",
    "            if tokenized_query[token:token+len(criteria)] == criteria:\n",
    "                labels[token:token+len(criteria)] = [\"include\"] * len(criteria)\n",
    "                \n",
    "    for criteria in tokenized_exclusion:\n",
    "        for token in range(int(len(tokenized_query)-len(criteria))+1):\n",
    "            if tokenized_query[token:token+len(criteria)] == criteria:\n",
    "                labels[token:token+len(criteria)] = [\"exclude\"] * len(criteria)\n",
    "    \n",
    "    final_labels.append(labels)\n",
    "\n",
    "df[\"labels\"] = final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating conversion dictionary\n",
    "tag_values = list(set(df[\"labels\"].values[0]))\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t:i for i, t in enumerate(tag_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "device = torch.device(\"cuda\")\n",
    "MAX_LEN = max([len(x) for x in df[\"labels\"]])\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating input data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(query) for query in df[\"query\"]]\n",
    "labels = list(df[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding inputs and converting tokens to ids\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Padding tags and converting to ids\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "# Creating masks\n",
    "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation split\n",
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
    "                                                            random_state=42, test_size=0.3)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all to tensors\n",
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader creation\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters for fine-tuning\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=3e-5,\n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 6\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.2261750185541038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  17%|█▋        | 1/6 [02:02<10:12, 122.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.07426624113450879\n",
      "Validation Accuracy: 0.9773437834596771\n",
      "Validation F1-Score: 0.9191636702623519\n",
      "\n",
      "Average train loss: 0.047599782480220565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 2/6 [04:04<08:09, 122.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.04606845586196236\n",
      "Validation Accuracy: 0.9863805730438134\n",
      "Validation F1-Score: 0.9528113784394523\n",
      "\n",
      "Average train loss: 0.021978420886128516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 3/6 [06:07<06:07, 122.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.03720182923438108\n",
      "Validation Accuracy: 0.9891644181763672\n",
      "Validation F1-Score: 0.9677162216022319\n",
      "\n",
      "Average train loss: 0.0101089846647317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 4/6 [08:09<04:04, 122.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.02997937945537674\n",
      "Validation Accuracy: 0.9918197781489572\n",
      "Validation F1-Score: 0.9751296714988695\n",
      "\n",
      "Average train loss: 0.005483067291243956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  83%|████████▎ | 5/6 [10:11<02:02, 122.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.029020959165949455\n",
      "Validation Accuracy: 0.9934900852284895\n",
      "Validation F1-Score: 0.9786723540389229\n",
      "\n",
      "Average train loss: 0.00283459022617096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 6/6 [12:13<00:00, 122.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.02848783687058249\n",
      "Validation Accuracy: 0.9934044284551801\n",
      "Validation F1-Score: 0.9773212379935966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_values, validation_loss_values = [], []\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Clip the norm of the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                            attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Move logits and labels to CPU\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    eval_loss = eval_loss / len(valid_dataloader)\n",
    "    validation_loss_values.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "    valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
    "plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"BERT.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BERT.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8254e40aa769>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BERT.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BERT.pth'"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"BERT.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither\t[CLS]\n",
      "Neither\twhat\n",
      "Neither\tare\n",
      "Neither\tthe\n",
      "Neither\tmost\n",
      "Neither\teffective\n",
      "Neither\ttreatments\n",
      "Neither\tfor\n",
      "Neither\tpatients\n",
      "Neither\twith\n",
      "include\tcardiac\n",
      "include\tarrest\n",
      "include\twith\n",
      "include\tsuccessful\n",
      "include\tresuscitation\n",
      "Neither\twho\n",
      "Neither\tpresent\n",
      "Neither\twith\n",
      "include\tvasospasm\n",
      "Neither\tbut\n",
      "Neither\tnot\n",
      "exclude\tloss\n",
      "exclude\tof\n",
      "exclude\tvoice\n",
      "Neither\tand\n",
      "Neither\tare\n",
      "Neither\tover\n",
      "Neither\tthe\n",
      "Neither\tage\n",
      "Neither\tof\n",
      "exclude\tage\n",
      "exclude\t=\n",
      "exclude\t95\n",
      "Neither\t[SEP]\n"
     ]
    }
   ],
   "source": [
    "number = 1\n",
    "sample = df[\"query\"][number]\n",
    "\n",
    "tokenized_sentence = tokenizer.encode(sample)\n",
    "input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_labels = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(tag_values[label_idx])\n",
    "        new_tokens.append(token)\n",
    "\n",
    "for token, label in zip(new_tokens, new_labels):\n",
    "    print(\"{}\\t{}\".format(label, token))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
